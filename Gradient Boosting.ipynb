{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b5817e-72fc-4494-b37f-0fa1ad3a3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, glob, time, joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, cohen_kappa_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d46855-7cb8-462e-bd3e-439ca7d27f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b077801-af6d-47ac-b734-102b85ac9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER TUNEABLE\n",
    "DATA_PATH = \"./Data/Scores\"   \n",
    "IMG_SIZE = 128\n",
    "TEST_SIZE = 0.20\n",
    "N_BOOTSTRAP = 500   \n",
    "SAVE_DIR = \"gb_artifacts\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2aead1-dc1e-4c31-b7d4-34c062f553fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total images found: 4297\n",
      "[INFO] Unique classes found: 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Data/Scores/Overlapped pencils/5/img1404-p-5...</td>\n",
       "      <td>Overlapped pencils_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Data/Scores/Star/3/img1903-ST-3(10011).png</td>\n",
       "      <td>Star_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Data/Scores/Overlapped pencils/6/img170-p-6.png</td>\n",
       "      <td>Overlapped pencils_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Data/Scores/Square/5/img1499-S-5.png</td>\n",
       "      <td>Square_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Data/Scores/Triangle/5/img1071-T-5.png</td>\n",
       "      <td>Triangle_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                 label\n",
       "0  ./Data/Scores/Overlapped pencils/5/img1404-p-5...  Overlapped pencils_5\n",
       "1       ./Data/Scores/Star/3/img1903-ST-3(10011).png                Star_3\n",
       "2  ./Data/Scores/Overlapped pencils/6/img170-p-6.png  Overlapped pencils_6\n",
       "3             ./Data/Scores/Square/5/img1499-S-5.png              Square_5\n",
       "4           ./Data/Scores/Triangle/5/img1071-T-5.png            Triangle_5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build df of image paths and labels\n",
    "paths, labels = [], []\n",
    "\n",
    "# Try two-level structure: ShapeName/Score/images\n",
    "two_level = False\n",
    "for shape_name in sorted(os.listdir(DATA_PATH)):\n",
    "    shape_path = os.path.join(DATA_PATH, shape_name)\n",
    "    if not os.path.isdir(shape_path):\n",
    "        continue\n",
    "    for score_name in sorted(os.listdir(shape_path)):\n",
    "        score_path = os.path.join(shape_path, score_name)\n",
    "        if os.path.isdir(score_path):\n",
    "            two_level = True\n",
    "            for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\"):\n",
    "                for p in glob.glob(os.path.join(score_path, ext)):\n",
    "                    paths.append(p)\n",
    "                    labels.append(f\"{shape_name}_{score_name}\")\n",
    "\n",
    "if not two_level:\n",
    "    # fallback: each folder under DATA_PATH is a class folder\n",
    "    for class_name in sorted(os.listdir(DATA_PATH)):\n",
    "        class_path = os.path.join(DATA_PATH, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\"):\n",
    "            for p in glob.glob(os.path.join(class_path, ext)):\n",
    "                paths.append(p)\n",
    "                labels.append(class_name)\n",
    "\n",
    "df = pd.DataFrame({\"path\": paths, \"label\": labels})\n",
    "df = df.sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)  # shuffle\n",
    "print(f\"[INFO] Total images found: {len(df)}\")\n",
    "print(f\"[INFO] Unique classes found: {df['label'].nunique()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d229256-bc55-459d-a4aa-3232bb1a7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Class counts (top 20):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "Square_5                540\n",
       "Triangle_5              539\n",
       "Diagonal_5              479\n",
       "Circle_4                457\n",
       "Wave_4                  434\n",
       "Overlapped circle_6     386\n",
       "Star_4                  250\n",
       "Overlapped pencils_6    226\n",
       "Overlapped pencils_5    143\n",
       "Overlapped circle_5     135\n",
       "Circle_3                112\n",
       "Wave_3                  109\n",
       "Star_3                  102\n",
       "Star_5                  100\n",
       "Diagonal_4               70\n",
       "Overlapped pencils_4     54\n",
       "Square_4                 45\n",
       "Triangle_4               38\n",
       "Star_0                   13\n",
       "Overlapped pencils_0     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Removing 3 class(es) with <2 samples: ['Overlapped circle_2', 'Circle_2', 'Square_0']\n",
      "[INFO] Final dataset size: 4294\n",
      "[INFO] Final number of classes: 31\n"
     ]
    }
   ],
   "source": [
    "# Show distribution and drop extremely rare classes\n",
    "counts = df['label'].value_counts()\n",
    "print(\"[INFO] Class counts (top 20):\")\n",
    "display(counts.head(20))\n",
    "\n",
    "# Identify classes with < 2 samples\n",
    "rare = counts[counts < 2].index.tolist()\n",
    "if rare:\n",
    "    print(f\"[WARNING] Removing {len(rare)} class(es) with <2 samples:\", rare)\n",
    "    df = df[~df['label'].isin(rare)].reset_index(drop=True)\n",
    "\n",
    "# Final class set\n",
    "print(\"[INFO] Final dataset size:\", len(df))\n",
    "print(\"[INFO] Final number of classes:\", df['label'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c39c113-c932-4a54-ac56-c429d69d38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction utilities\n",
    "def load_and_resize(path, img_size=IMG_SIZE):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def hu_moments(img):\n",
    "    moments = cv2.moments(img)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    # log transform to stabilize\n",
    "    hu_signed = -np.sign(hu) * np.log10(np.abs(hu) + 1e-12)\n",
    "    return hu_signed\n",
    "\n",
    "def area_ratio(img):\n",
    "    # assumes darker strokes on lighter background â€” adapt if opposite\n",
    "    _, bw = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # count non-background pixels: if strokes are dark, pixels==0 are strokes\n",
    "    strokes = np.sum(bw == 0)\n",
    "    return np.array([strokes / (img.shape[0] * img.shape[1] + 1e-9)])\n",
    "\n",
    "def hog_vector(img):\n",
    "    # skimage.hog expects float in [0,1] (works with 0..255 too but normalize)\n",
    "    img_f = img.astype(\"float32\") / 255.0\n",
    "    vec = hog(img_f,\n",
    "              orientations=9,\n",
    "              pixels_per_cell=(8,8),\n",
    "              cells_per_block=(2,2),\n",
    "              block_norm='L2-Hys',\n",
    "              feature_vector=True)\n",
    "    return vec\n",
    "\n",
    "def extract_features_for_path(path):\n",
    "    img = load_and_resize(path)\n",
    "    h = hog_vector(img)\n",
    "    hu = hu_moments(img)\n",
    "    ar = area_ratio(img)\n",
    "    feat = np.concatenate([h, hu, ar])\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148eae0e-0804-43c4-acfe-034ab71d012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahabur-alam/anaconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Extracting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4294/4294 [00:53<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Feature matrix shape: (4294, 8108)\n",
      "[INFO] Classes: [np.str_('Circle_0'), np.str_('Circle_3'), np.str_('Circle_4'), np.str_('Diagonal_0'), np.str_('Diagonal_3'), np.str_('Diagonal_4'), np.str_('Diagonal_5'), np.str_('Overlapped circle_0'), np.str_('Overlapped circle_4'), np.str_('Overlapped circle_5'), np.str_('Overlapped circle_6'), np.str_('Overlapped pencils_0'), np.str_('Overlapped pencils_2'), np.str_('Overlapped pencils_3'), np.str_('Overlapped pencils_4'), np.str_('Overlapped pencils_5'), np.str_('Overlapped pencils_6'), np.str_('Square_4'), np.str_('Square_5'), np.str_('Star_0'), np.str_('Star_2'), np.str_('Star_3'), np.str_('Star_4'), np.str_('Star_5'), np.str_('Triangle_0'), np.str_('Triangle_4'), np.str_('Triangle_5'), np.str_('Wave_0'), np.str_('Wave_2'), np.str_('Wave_3'), np.str_('Wave_4')]\n"
     ]
    }
   ],
   "source": [
    "# feature matrix\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "feats = []\n",
    "labs = []\n",
    "failed = 0\n",
    "for p, lab in tqdm(zip(df['path'], df['label']), total=len(df), desc=\"Extracting\"):\n",
    "    try:\n",
    "        feats.append(extract_features_for_path(p))\n",
    "        labs.append(lab)\n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        print(\"Failed:\", p, e)\n",
    "\n",
    "if failed:\n",
    "    print(f\"[WARN] Failed to process {failed} images\")\n",
    "\n",
    "X = np.vstack(feats)\n",
    "y_labels = np.array(labs)\n",
    "print(\"[INFO] Feature matrix shape:\", X.shape)\n",
    "\n",
    "# Label encode\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_labels)\n",
    "print(\"[INFO] Classes:\", list(le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25bb41e8-45ad-4811-b0b0-916743b0f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3435, 8108) Test shape: (859, 8108)\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "cnts = Counter(y)\n",
    "if min(cnts.values()) < 2:\n",
    "    raise ValueError(\"There is still at least one class with <2 samples; adjust dataset or remove rare classes.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9736fca5-2552-4d89-8127-574be4d721f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Example class weights (train): {np.int64(26): 0.002, np.int64(22): 0.005, np.int64(2): 0.003, np.int64(9): 0.009, np.int64(23): 0.013, np.int64(18): 0.002, np.int64(29): 0.011, np.int64(6): 0.003, np.int64(17): 0.028, np.int64(11): 0.1, np.int64(10): 0.003, np.int64(16): 0.006, np.int64(25): 0.033, np.int64(30): 0.003, np.int64(3): 0.333, np.int64(1): 0.011, np.int64(21): 0.012, np.int64(5): 0.018, np.int64(15): 0.009, np.int64(20): 0.167, np.int64(19): 0.1, np.int64(14): 0.023, np.int64(13): 0.167, np.int64(8): 0.143, np.int64(27): 0.5, np.int64(0): 0.25, np.int64(4): 0.5, np.int64(28): 0.333, np.int64(7): 0.5, np.int64(24): 0.333, np.int64(12): 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Compute sample weights inversely proportional to class frequency (for GB fit)\n",
    "class_freq = Counter(y_train)\n",
    "class_weights = {cls: 1.0 / freq for cls, freq in class_freq.items()}\n",
    "sample_weight = np.array([class_weights[lab] for lab in y_train])\n",
    "print(\"[INFO] Example class weights (train):\", {k: round(v,3) for k,v in class_weights.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff74d9-13ab-48ec-9313-15539717d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "start = time.time()\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"[INFO] Training finished in {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae665a90-10ef-4946-99aa-d035b4825141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = gb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc292f8-8f40-4f98-9e19-dd64522af0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit metrics to classes present in y_test\n",
    "unique_test_labels = np.unique(y_test)\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    labels=unique_test_labels,\n",
    "    target_names=le.classes_[unique_test_labels],\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df5e1e-1936-4989-ad0d-0a5b67bd184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=unique_test_labels)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_[unique_test_labels],\n",
    "            yticklabels=le.classes_[unique_test_labels], cmap='Blues')\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix (GB)\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b2dad-22d6-4ad4-81b1-c342cddf7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Weighted Kappa + bootstrap CI\n",
    "def qwk(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def bootstrap_qwk_ci(y_true, y_pred, n_boot=N_BOOTSTRAP, seed=RANDOM_SEED):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = len(y_true)\n",
    "    vals = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.randint(0, n, n)\n",
    "        vals.append(qwk(y_true[idx], y_pred[idx]))\n",
    "    vals = np.array(vals)\n",
    "    return qwk(y_true, y_pred), np.percentile(vals, 2.5), np.percentile(vals, 97.5)\n",
    "\n",
    "qwk_val, qwk_lo, qwk_hi = bootstrap_qwk_ci(y_test, y_pred)\n",
    "print(f\"QWK: {qwk_val:.4f} (95% CI: {qwk_lo:.4f} - {qwk_hi:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb12662-cbc0-4e67-b848-956e81651687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = gb.feature_importances_\n",
    "topk = 20\n",
    "indices = np.argsort(importances)[::-1][:topk]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(topk)[::-1], importances[indices][::-1])\n",
    "plt.yticks(range(topk)[::-1], [f\"F{idx}\" for idx in indices[::-1]])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 20 feature importances (Gradient Boosting)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Map block: show which indices correspond to Hu moments and Area (approx.)\n",
    "hog_len = len(hog_vector(np.zeros((IMG_SIZE,IMG_SIZE), dtype=np.uint8)))\n",
    "print(f\"[INFO] HOG length: {hog_len}, total features: {X.shape[1]}\")\n",
    "print(f\"[INFO] Hu indices approximately: {list(range(hog_len, hog_len+7))}\")\n",
    "print(f\"[INFO] Area index approximately: {hog_len+7}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1c4e6-a191-4b0b-8fb6-d957342e5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "model_path = os.path.join(SAVE_DIR, \"gb_model.joblib\")\n",
    "le_path = os.path.join(SAVE_DIR, \"label_encoder.joblib\")\n",
    "joblib.dump(gb, model_path)\n",
    "joblib.dump(le, le_path)\n",
    "print(\"[INFO] Saved model to:\", model_path)\n",
    "print(\"[INFO] Saved label encoder to:\", le_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef12b33-1fa4-467e-92cc-e7b007cc1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict helper\n",
    "def predict_image_gb(img_path, model=gb, label_encoder=le):\n",
    "    feat = extract_features_for_path(img_path).reshape(1,-1)\n",
    "    pred_idx = model.predict(feat)[0]\n",
    "    proba = model.predict_proba(feat)[0] if hasattr(model, \"predict_proba\") else None\n",
    "    label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    return {\"pred_idx\": int(pred_idx), \"label\": label, \"proba\": proba}\n",
    "\n",
    "# Example\n",
    "# res = predict_image_gb(\"Data/Scores/Circle/2/sample1.png\")\n",
    "# print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
