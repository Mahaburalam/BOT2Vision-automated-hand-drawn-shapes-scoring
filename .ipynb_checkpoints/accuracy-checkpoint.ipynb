{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a11090c3-470c-4af0-8453-fb3606272c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a635aafc-6d9b-4e0f-bf48-4f22264c6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_SIZE = 128\n",
    "DATA_PATH = \"./Data/Scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddbeb785-bad3-40cf-93e0-124255dc18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset...\n",
      "[INFO] Dataset loaded: 4297 samples, 34 classes\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 3: Load Dataset\n",
    "# ==============================\n",
    "X, y, class_names = [], [], []\n",
    "class_map = {}\n",
    "\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "\n",
    "for shape_name in os.listdir(DATA_PATH):  # e.g., Circle, Square\n",
    "    shape_path = os.path.join(DATA_PATH, shape_name)\n",
    "    if not os.path.isdir(shape_path):\n",
    "        continue\n",
    "\n",
    "    for score in os.listdir(shape_path):  # e.g., 0,1,2...\n",
    "        score_path = os.path.join(shape_path, score)\n",
    "        if not os.path.isdir(score_path):\n",
    "            continue\n",
    "\n",
    "        label = f\"{shape_name}_{score}\"\n",
    "        if label not in class_map:\n",
    "            class_map[label] = len(class_map)\n",
    "            class_names.append(label)\n",
    "\n",
    "        for file in os.listdir(score_path):\n",
    "            if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                path = os.path.join(score_path, file)\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                X.append(img)\n",
    "                y.append(class_map[label])\n",
    "\n",
    "X = np.array(X, dtype=\"float32\") / 255.0\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"[INFO] Dataset loaded: {X.shape[0]} samples, {len(class_map)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3888b8-d991-4f09-a731-dfbaee0a83e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Class distribution before filtering:\n",
      "Class Triangle_0: 3 samples\n",
      "Class Triangle_4: 38 samples\n",
      "Class Triangle_5: 539 samples\n",
      "Class Star_3: 102 samples\n",
      "Class Star_2: 8 samples\n",
      "Class Star_0: 13 samples\n",
      "Class Star_4: 250 samples\n",
      "Class Star_5: 100 samples\n",
      "Class Wave_3: 109 samples\n",
      "Class Wave_2: 4 samples\n",
      "Class Wave_0: 2 samples\n",
      "Class Wave_4: 434 samples\n",
      "Class Circle_3: 112 samples\n",
      "Class Circle_2: 1 samples\n",
      "Class Circle_0: 5 samples\n",
      "Class Circle_4: 457 samples\n",
      "Class Square_0: 1 samples\n",
      "Class Square_4: 45 samples\n",
      "Class Square_5: 540 samples\n",
      "Class Overlapped pencils_3: 8 samples\n",
      "Class Overlapped pencils_2: 2 samples\n",
      "Class Overlapped pencils_0: 12 samples\n",
      "Class Overlapped pencils_4: 54 samples\n",
      "Class Overlapped pencils_6: 226 samples\n",
      "Class Overlapped pencils_5: 143 samples\n",
      "Class Overlapped circle_2: 1 samples\n",
      "Class Overlapped circle_0: 3 samples\n",
      "Class Overlapped circle_4: 9 samples\n",
      "Class Overlapped circle_6: 386 samples\n",
      "Class Overlapped circle_5: 135 samples\n",
      "Class Diagonal_3: 2 samples\n",
      "Class Diagonal_0: 4 samples\n",
      "Class Diagonal_4: 70 samples\n",
      "Class Diagonal_5: 479 samples\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 4: Check Class Distribution\n",
    "# ==============================\n",
    "class_counts = Counter(y)\n",
    "print(\"\\n[INFO] Class distribution before filtering:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"Class {class_names[cls]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8895c224-bedd-4853-9bda-dcd14e1d1bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] After filtering: 4294 samples, 31 classes\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 5: Filter Rare Classes (< 2 samples)\n",
    "# ==============================\n",
    "valid_classes = [cls for cls, count in class_counts.items() if count >= 2]\n",
    "mask = np.isin(y, valid_classes)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"\\n[INFO] After filtering: {X.shape[0]} samples, {len(set(y))} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e035d5b5-e28b-4092-99a3-ae48ecb61a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training set: 3435 samples\n",
      "[INFO] Test set: 859 samples\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 6: Train-Test Split\n",
    "# ==============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"[INFO] Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2e7ce2-0c41-432b-841c-d901b8fdc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# STEP 7: Feature Extraction (Flatten Images)\n",
    "# ==============================\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab84ec7-6b06-4cf0-8b6e-1120daa8d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Training Random Forest...\n",
      "[RESULT] Random Forest Accuracy: 0.5448\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 27, does not match size of target_names, 31. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m acc_rf \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_rf)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[RESULT] Random Forest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_rf\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_rf, target_names\u001b[38;5;241m=\u001b[39m[class_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2693\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2687\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2689\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2690\u001b[0m             )\n\u001b[1;32m   2691\u001b[0m         )\n\u001b[1;32m   2692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2697\u001b[0m         )\n\u001b[1;32m   2698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2699\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 27, does not match size of target_names, 31. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 8A: Random Forest\n",
    "# ==============================\n",
    "print(\"\\n[INFO] Training Random Forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_flat, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_flat)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"[RESULT] Random Forest Accuracy: {acc_rf:.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[class_names[i] for i in np.unique(y)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f0edb5-1afe-4dde-9f2b-ac82cf940561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Training Gradient Boosting...\n",
      "[RESULT] Gradient Boosting Accuracy: 0.4796\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 30, does not match size of target_names, 31. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m acc_gb \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_gb)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[RESULT] Gradient Boosting Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_gb\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_gb, target_names\u001b[38;5;241m=\u001b[39m[class_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2693\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2687\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2689\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2690\u001b[0m             )\n\u001b[1;32m   2691\u001b[0m         )\n\u001b[1;32m   2692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2697\u001b[0m         )\n\u001b[1;32m   2698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2699\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 30, does not match size of target_names, 31. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 8B: Gradient Boosting\n",
    "# ==============================\n",
    "print(\"\\n[INFO] Training Gradient Boosting...\")\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train_flat, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(X_test_flat)\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"[RESULT] Gradient Boosting Accuracy: {acc_gb:.4f}\")\n",
    "print(classification_report(y_test, y_pred_gb, target_names=[class_names[i] for i in np.unique(y)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdb3e0-74d2-4fee-85ff-7ae940f561f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
